{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e6fd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "# from sentence_transformers import util\n",
    "import time\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import random\n",
    "from  functions import get_IDF_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85eaa3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING DEVICE: cuda / NVIDIA GeForce RTX 5060\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"USING DEVICE: {device} / {torch.cuda.get_device_name() if torch.cuda.is_available() else None}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7cded22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset / model / hyperparameters\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\").to(device)\n",
    "\n",
    "dataset = pd.read_csv(\"fra_cleaned.csv\",sep = \";\" , encoding= 'unicode_escape', on_bad_lines='skip')\n",
    "\n",
    "IDF_weight = get_IDF_weights(dataset)\n",
    "key = IDF_weight.keys()\n",
    "\n",
    "layer_weights = torch.tensor([[0.8, 0.25, 0.1],\n",
    "                            [0.25, 1., 0.35], \n",
    "                            [0.1, 0.35, 1.2]], device=device)\n",
    "layer_weights = layer_weights / torch.sum(layer_weights)\n",
    "\n",
    "iteration = 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b38c63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcess:\n",
    "    def __init__(self, model, device, dataset, IDF_weights = None):\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        self.device = device\n",
    "        self.note_embedding_cache = {}\n",
    "        self.IDF_weight = IDF_weights if IDF_weights is not None else {note: 1. for note in key}\n",
    "\n",
    "    def get_note_embedding(self, note):\n",
    "        if note not in self.note_embedding_cache:\n",
    "            self.note_embedding_cache[note] = self.model.encode(\n",
    "                note, convert_to_tensor=True, device=self.device\n",
    "            )\n",
    "        return self.note_embedding_cache[note]\n",
    "    \n",
    "    def process_notes(self, note_dict, IDF_weights):\n",
    "        processed_notes = {}\n",
    "        for k , v in note_dict.items():\n",
    "            temp = [n.strip() for n in v.split(\",\")] # Remove extra spaces\n",
    "            weight = torch.tensor([IDF_weights[w] for w in temp]).unsqueeze(1) # Get IDF weights\n",
    "            weight = weight / torch.sum(weight)  # Normalize weights\n",
    "            weight = weight.to(self.device) # Move weight to device(GPU/CPU)\n",
    "            embeddings = torch.stack([self.get_note_embedding(n) for n in temp])\n",
    "            processed_notes[k] = torch.sum(embeddings * weight, dim=0) # Compute weighted average embeddings\n",
    "        \n",
    "        weighted_embeddings = torch.vstack(list(processed_notes.values()))\n",
    "        return weighted_embeddings # shape = (3,384)\n",
    "\n",
    "    def get_emb_dict(self):\n",
    "        emb_DB = {}\n",
    "        for idx in range(len(self.dataset)):\n",
    "            name = self.dataset.at[idx, \"Perfume\"]\n",
    "            notes = {\n",
    "                \"Top\": self.dataset.at[idx, \"Top\"],\n",
    "                \"Middle\": self.dataset.at[idx, \"Middle\"],\n",
    "                \"Base\": self.dataset.at[idx, \"Base\"],\n",
    "            }\n",
    "            note_embeddings = self.process_notes(notes, self.IDF_weight)\n",
    "            emb_DB[name] = note_embeddings\n",
    "        return emb_DB\n",
    "    \n",
    "    def dict_to_tensor(self, emb_DB):\n",
    "        names = list(emb_DB.keys())\n",
    "        tensors = list(emb_DB.values())\n",
    "        embeddings = torch.stack(tensors)\n",
    "        embeddings = embeddings.to(self.device)\n",
    "        return names, embeddings\n",
    "\n",
    "preprocessor = PreProcess(model, device, dataset, IDF_weights = IDF_weight)\n",
    "emb_DB = preprocessor.get_emb_dict()\n",
    "names, DB_batch = preprocessor.dict_to_tensor(emb_DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b22bd08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perfume_Recommender(PreProcess):\n",
    "    def __init__(self, dataset, model, device, layer_weights, DB_batch):\n",
    "        self.dataset = dataset\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.layer_weights = layer_weights\n",
    "        self.note_embedding_cache = {}\n",
    "        self.DB_batch = DB_batch\n",
    "\n",
    "    def timer(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            start_time = time.time()\n",
    "            result = func(*args, **kwargs)\n",
    "            end_time = time.time()\n",
    "            print(f\"Duration: {end_time - start_time:.4f} seconds\")\n",
    "            return result\n",
    "        return wrapper\n",
    "    \n",
    "    '''\n",
    "    def get_cosine_similarity(self, emb1, emb2, layer_weights):\n",
    "        # emb.shape = (3, 384)\n",
    "        cosine_scores = util.cos_sim(emb1, emb2)\n",
    "        score = torch.sum(cosine_scores * layer_weights).item() / torch.sum(layer_weights).item()\n",
    "        return score\n",
    "    '''\n",
    "\n",
    "    @timer\n",
    "    def recommend_idx(self, query_idx = \"random\", n_recommendations=5):\n",
    "        if query_idx == \"random\":\n",
    "            query_idx = random.randint(0, len(self.dataset) - 1)\n",
    "\n",
    "        target_name = self.dataset.at[query_idx, \"Perfume\"]\n",
    "        target_notes = {\"Top\": self.dataset.at[query_idx, \"Top\"],\n",
    "                  \"Middle\": self.dataset.at[query_idx, \"Middle\"],\n",
    "                  \"Base\": self.dataset.at[query_idx, \"Base\"]}\n",
    "        weighted_embeddings_target = self.process_notes(target_notes, IDF_weight)\n",
    "        \n",
    "        q_norm = nn.functional.normalize(weighted_embeddings_target, p=2, dim=1) # shape = (3,384)\n",
    "        db_norm = nn.functional.normalize(self.DB_batch, p=2, dim=2) # shape = (n_of_DB,3,384)\n",
    "\n",
    "        similarity_map = torch.einsum('id, bjd -> bij', q_norm, db_norm)  # shape = (n_of_DB, 3, 3)\n",
    "        scores = (similarity_map * self.layer_weights).sum(dim=(1, 2))\n",
    "        top_scores, top_indices = torch.topk(scores, k=n_recommendations+1)\n",
    "        return target_notes, target_name, top_scores, top_indices # top_scores: tensor, top_indices: tensor\n",
    "    \n",
    "    def recommend(self, query_notes, n_recommendations=5):\n",
    "        weighted_embeddings_target = self.process_notes(query_notes, IDF_weight)\n",
    "        \n",
    "        q_norm = nn.functional.normalize(weighted_embeddings_target, p=2, dim=1) # shape = (3,384)\n",
    "        db_norm = nn.functional.normalize(self.DB_batch, p=2, dim=2) # shape = (n_of_DB,3,384)\n",
    "\n",
    "        similarity_map = torch.einsum('id, bjd -> bij', q_norm, db_norm)  # shape = (n_of_DB, 3, 3)\n",
    "        scores = (similarity_map * self.layer_weights).sum(dim=(1, 2))\n",
    "        top_scores, top_indices = torch.topk(scores, k=n_recommendations+1)\n",
    "        return query_notes, top_scores, top_indices # top_scores: tensor, top_indices: tensor\n",
    "\n",
    "    \n",
    "    def display_recommendations(self, target_notes, target_name, top_scores, top_indices, note_comparison=True):\n",
    "        top_idx = top_indices.tolist()\n",
    "        top_similars = [names[i]for i in top_idx]\n",
    "\n",
    "        if target_name in top_similars:\n",
    "            top_similars.remove(target_name)\n",
    "        else:\n",
    "            top_similars = top_similars[:-1]\n",
    "\n",
    "        print(\"***\" * 10, \"results\", \"***\" * 10)\n",
    "        print(f\">>Original Perfume: {target_name} @ {dataset.loc[dataset['Perfume'].str.strip() == target_name, 'Brand'].values[0] if target_name in dataset['Perfume'].values else 'Unknown Brand'}\")\n",
    "        print(f\">>most similar perfume: {top_similars[0]} @ {dataset.loc[dataset['Perfume'].str.strip() == top_similars[0], 'Brand'].values[0]}\")\n",
    "        print(\"---\" * 10)\n",
    "        print(\">>Top 5 similar perfumes:\")\n",
    "        for i, perfume in enumerate(top_similars):\n",
    "            print(f\"NO.{i+1} {perfume} / Similarity Score: {top_scores[i].item():.2f}\")\n",
    "        print()\n",
    "        if note_comparison:\n",
    "            print(\"---\" * 10,\"\\n\")\n",
    "            print(f\">>Most Similar Perfume except Original Perfume: {top_similars[0]}\")\n",
    "            print(f\"Top Notes: {dataset.loc[dataset['Perfume'].str.strip() == top_similars[0], 'Top'].values[0]}\")\n",
    "            print(f\"Middle Notes: {dataset.loc[dataset['Perfume'].str.strip() == top_similars[0], 'Middle'].values[0]}\")\n",
    "            print(f\"Base Notes: {dataset.loc[dataset['Perfume'].str.strip() == top_similars[0], 'Base'].values[0]}\")\n",
    "            print(\"---\" * 10)\n",
    "            print(f\">>Original Perfume: {target_name}\")\n",
    "            for k, v in target_notes.items():\n",
    "                print(f\"{k} Notes: {v}\")\n",
    "            print(\"---\" * 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3e61b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** results ******************************\n",
      ">>Original Perfume: Custom Query @ Unknown Brand\n",
      ">>most similar perfume: velvet-imari @ avon\n",
      "------------------------------\n",
      ">>Top 5 similar perfumes:\n",
      "NO.1 velvet-imari / Similarity Score: 0.79\n",
      "NO.2 little-black-dress-party / Similarity Score: 0.77\n",
      "NO.3 emilie-parfum / Similarity Score: 0.77\n",
      "NO.4 vf-bloom / Similarity Score: 0.77\n",
      "NO.5 noir-endurance / Similarity Score: 0.76\n",
      "\n",
      "------------------------------ \n",
      "\n",
      ">>Most Similar Perfume except Original Perfume: velvet-imari\n",
      "Top Notes: bergamot, mandarin orange\n",
      "Middle Notes: rose, jasmine, lily-of-the-valley\n",
      "Base Notes: amber, musk, vanilla\n",
      "------------------------------\n",
      ">>Original Perfume: Custom Query\n",
      "Top Notes: bergamot, lemon, orange\n",
      "Middle Notes: rose, jasmine, lily of the valley\n",
      "Base Notes: musk, amber, vanilla\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    query_notes = {\n",
    "        \"Top\": \"bergamot, lemon, orange\",\n",
    "        \"Middle\": \"rose, jasmine, lily of the valley\",\n",
    "        \"Base\": \"musk, amber, vanilla\"\n",
    "    }\n",
    "\n",
    "    recommender = Perfume_Recommender(\n",
    "            dataset = dataset,\n",
    "            model = model,\n",
    "            device = device,\n",
    "            layer_weights = layer_weights,\n",
    "            DB_batch = DB_batch)\n",
    "    query_notes, top_scores, top_indices = recommender.recommend(query_notes=query_notes, n_recommendations=5)\n",
    "    recommender.display_recommendations(query_notes, \"Custom Query\", top_scores, top_indices, note_comparison=True)\n",
    "  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
